---
layout:     post
title:      从零开始学大数据
subtitle:   Day01
date:       2020-03-10
author:     KaithyXu
header-img: img/elephant.jpg
catalog: true
tags:
    - Big Data
---

## 记录
自己有好多不懂的技术，好在自己还年轻，什么都可以尝试，所以打算通过写博客的方式倒逼自己学习，博客会记录自己的学习经历，包括付费课程，博客，书籍等等。
这是从零开始系列的第一天，往后的日子还有很长，希望自己能够一直坚持下去，不要忘记自己的初心，努力成为一个技术大牛！

## Hadoop
### 极客时间系列
最近在通过极客时间学习大数据，所以就先以这个作为起点。
#### RAID磁盘阵列
RAID,独立磁盘冗余阵列，将多块普通的磁盘组成一个阵列，共同对外提供服务。主要是为了改善磁盘的存储容量，读写速度，增强磁盘的可用性和容错能力
分类：
* RAID0: 根据磁盘数将数据分为N份，并发写入到这N块磁盘上
* RAID1: 同一份数据写入到两块磁盘，即备份
* RAID10: 所有磁盘N分为两份A、B，数据A、B中各保存一份完整的内容，同时，在A、B内部，利用RAID0来进行并发写
* RAID3: 在数据写入磁盘时，将数据分为N-1份，并发写入N-1块磁盘，并在第N块磁盘上记录校验数据
* RAID5: 与RAID3相似，只是校验数据采用螺旋写入所有磁盘中的方式
* RAID6: 与RAID5类似，只是数据并发写入N-2块磁盘，并螺旋式的在剩余两块磁盘中写入校验信息（校验信息使用不同的算法生成）

#### HDFS(分布式文件系统)
HDFS分为两种角色NameNode与DataNode
* DataNode: 负责文件数据的存储与读写操作，HDFS将文件数据分割成若干数据块(Block),每个DataNode存储一部分数据块

* NameNode: 负责整个分布式文件系统的元数据（MetaData）管理，元数据包括文件路径名、数据块的ID以及存储位置等信息

HDFS架构图：
![](https://hadoop.apache.org/docs/r1.0.4/cn/images/hdfsarchitecture.gif)

#### MapReduce
理解Hadoop我个人觉得比较重要的一点就是：移动计算比移动数据更划算
传统的开发模式中，是将数据从数据库中取出来，然后再进行一些业务处理，所以一开始在学习Hadoop的时候，我也惯性的这么认为了，好在在学习课程时，老师写了这句话后，之前学习的很多不太明白的地方有了新的感觉，突然间明白了自己在学习大数据时应该做什么。
在课程中老师提到，MapReduce既是编程模型，也是计算框架，以下简称为MR，MR定义了我们的开发模型，规范了我们该如何去开发一个计算程序，而不用去考虑如何执行这个计算程序，就像是一个黑盒，把东西给它，然后拿到想要的结果。
以下是我自己第一次尝试使用Hadoop自带的WordCount程序实现统计功能的经历：
要统计的文件内容如下：
文件名: pv_users
文件内容：
```
1,25
2,25
1,32
2,25

```
1. 通过hdfs将文件上传到DataNode中

```
hdfs dfs -put pv_users data_users

```
2. 利用Hadoop提供的hadoop-mapreduce-examples-3.2.1.jar wordcount进行wordcount

```
yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar wordcount data_users data_users_count
```
3. 执行成功后会在data_users_count目录下生成两个文件
可以通过ls命令查看
```
hdfs dfs -ls data_users_count
```
结果：
```
-rw-r--r--   1 root supergroup          0 2020-03-10 12:18 data_users_count/_SUCCESS
-rw-r--r--   1 root supergroup         56 2020-03-10 12:18 data_users_count/part-r-00000
```
其中data_users_count/part-r-00000文件中记录了统计数据，可以使用cat命令查看文件内容

```
hdfs dfs -cat data_users_count/part-r-00000
```