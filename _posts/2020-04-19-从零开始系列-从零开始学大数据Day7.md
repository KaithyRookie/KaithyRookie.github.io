---
layout:     post
title:      从零开始学大数据
subtitle:   Day7
date:       2020-04-19
author:     KaithyXu
header-img: img/fog.jpg
catalog: true
tags:
    - Big Data
---

## MapReduce -- 《Hadoop权威指南》

### YARN简介
YARN通过两类长期运行的守护进程提供自己的核心服务：管理集群上资源使用的资源管理器（resource manager）、运行在集群中所有节点上能够启动和监控容器的节点管理器(node manager)
![](https://github.com/KaithyRookie/KaithyRookie/blob/master/imgs/yarn.jpg)

#### 工作流程：
1. 客户端与Resource Manager通信，请求运行一个application master进程(即自定义的应用程序)
2. Resource Manager分配一个node manager以运行application master；一旦application master运行起来后，行为完全由应用本身决定，

#### Yarn工作模型：
* 一个用户作业对应一个应用，如MR
* 作业的每一个工作流或每个用户对话对应一个应用，例如Spark
* 多个用户共享一个长期运行的应用，如Apache Slider

#### Yarn的优势：
* 可扩展性：利用其资源管理器和application master分离的架构优点
* 可用性
* 利用率：一个node manager管理一个资源池，应用可以按需申请资源
* 多租户

#### Yarn调度器：
* FIFO调度器
* 容量调度器：使用一个专门队列保证小作业一提交就可以启动（YARN的默认选项）,在capacity-scheduler.xml分配文件中对各个队列的资源占比进行配置
* 公平调度器：不需要预留一定量的资源，当小作业启动后，且前一个大作业使用的容器用完病释放资源时，会被分配给小作业，当小作业使用完成并释放后，大作业将会再次使用这些资源。启用需要将 yarn-site.xml文件中的yarn.resourcemanager.scheduler.class 设置为 org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler; 并通过一个名为fair-scheduler.xml的分配文件进行公平调度器的配置，支持FIFO策略 和 Dominant Resource Fairness策略

### Hadoop的I/O操作
#### 数据完整性校验：
HDFS 会对写入的所有数据计算校验和，并在读取数据时验证校验和，其针对每个由dfs.bytes-per-checksum 指定的数据计算校验和，默认为512个字节

* datanode负责在接收到数据后存储该数据及其校验和之前对数据进行验证
* client从datanode读取数据时，也会计算校验和，并与datanode中存储的校验和进行比较
* 每个datanode会在后台线程中运行一个DataBlockScanner，定期验证存储在这个datanode上的所有数据块

#### 压缩

codec：压缩-解压算法的一种实现
CompressionCodec：包含两个函数 createOutputStream,返回一个CompressionOutputStream对象，用于将未压缩的数据，使用指定压缩格式进行压缩输出，createInputStream则返回一个CompressionInputStream 用于解压缩

```
private void codec(String[] args) throws ClassNotFoundException, IOException {
    String codecClassName = args[0];
    Class<?> codecClass = Class.forName(codecClassName);


    Configuration conf = new Configuration();
    CompressionCodec codec = (CompressionCodec) ReflectionUtils.newInstance(codecClass, conf);


    CompressionOutputStream out = codec.createOutputStream(System.out);


    IOUtils.copyBytes(System.in,out,4096, false);
    out.flush();
}

```

CompressionFactory 提供了通过压缩文件扩展名来推断出CompressionCodec的方法 getCodec(Path path)

```
private void acquireCodecByFactory(String[] args) throws IOException {
    String uri = args[0];
    Configuration conf = new Configuration();


    FileSystem fs = FileSystem.get(URI.create(uri), conf);
    
    Path inputPath = new Path(uri);


    CompressionCodecFactory factory = new CompressionCodecFactory(conf);
    CompressionCodec codec = factory.getCodec(inputPath);
    
    if(null == codec) {
        System.err.println("No codec found for uri: "+uri);
        System.exit(1);
    }
    
    String outputUri = CompressionCodecFactory.removeSuffix(uri, codec.getDefaultExtension());


    InputStream in = null;


    OutputStream out = null;
    
    try {
        in = codec.createInputStream(fs.open(inputPath));
        
        out = fs.create(new Path(outputUri));
        IOUtils.copyBytes(in, out, conf);
    }finally {
        if(null != in ) 
            IOUtils.closeStream(in);
        if(null != out)
            IOUtils.closeStream(out);
    }
    
}

```

若应用中需要执行大量的压缩与解压操作，可以考虑使用CodecPool，其支持反腐使用压缩和解压， 以分摊创建这些对象的开销,通过finally 语句块中返回compressor以实现不同数据流之间来回复制数据

```
private void useCodecPool(String[] args) throws ClassNotFoundException, IOException {
    String codecClassName = args[0];
    Class<?> codecClass = Class.forName(codecClassName);


    Configuration conf = new Configuration();
    CompressionCodec codec = (CompressionCodec) ReflectionUtils.newInstance(codecClass, conf);


    Compressor compressor = null;
    
    try {
        compressor = CodecPool.getCompressor(codec);
        CompressionOutputStream out = codec.createOutputStream(System.out);


        IOUtils.copyBytes(System.in,out,4096, false);
        out.flush();
    }finally {
        if(null != compressor)
            CodecPool.returnCompressor(compressor);
    }
    
}

```

#### 压缩与分片
如何选择那种压缩格式（从上至下性能依次降低）：
1. 使用容器文件格式，如顺序文件、Avro数据文件、ORCFiles或者Parquet文件等同时支持压缩和切分的文件时，通常与一个快速压缩工具联合使用，如LZO，LZ4或者Snappy
2. 使用支持切分的压缩格式，如bzip2或者使用通过索引实现切分的压缩格式，如LZO
3. 在应用程序中先将文件切分成块，在使用任意的压缩格式将每个数据块建立对应的压缩文件(需要控制切割的文件块的大小，以确保压缩后文件的大小近似于HDFS块的大小)
4. 直接存储未压缩的文件

MR中使用压缩，两种方案
* 在作业配置过程中，将mapreduce.output.fileoutputformat.compress 属性设置为true
* 在FileOutputFormat中使用setCompressOutput 与setOutputCompressorClass进行设置

```
FileOutputFormat.setCompressOutput(job,true);
FileOutputFormat.setOutputCompressorClass(job, GzipCodec.class);

```

#### MR的压缩属性


| 属性名称 | 类型 | 默认值 |
| --- | --- | --- |
| mapreduce.output.fileoutputformat.compress | boolean | false |
| mapreduce.output.fileoutputformat.compress.codec | 类名称 | org.apache.hadoop.io.compress.DefaultCodec |
| mapreduce.output.fileoutputformat.compress.type | String | RECORD |

对map任务输出进行压缩

| 属性名称 | 类型 | 默认值 | 描述 |
| --- | --- | --- | --- |
| mapreduce.map.output.compress | boolean | false | 是否对map任务输出进行压缩 |
| mapreduce.map.output.compress.codec | Class | org.apache.hadoop.io.compress.DefaultCodec | map输出所用的codec |

程序中控制代码
```
Configuration conf = new Configuration();

conf.setBoolean(MRJobConfig.MAP_OUTPUT_COMPRESS, true);
conf.setClass(MRJobConfig.MAP_OUTPUT_COMPRESS_CODEC, GzipCodec.class, CompressionCodec.class);
Job job = Job.getInstance(conf);

```