---
layout:     post
title:      从零开始学大数据
subtitle:   Day2
date:       2020-03-12
author:     KaithyXu
header-img: img/elephant2.jpg
catalog: true
tags:
    - Big Data
---

## 记录
自己有好多不懂的技术，好在自己还年轻，什么都可以尝试，所以打算通过写博客的方式倒逼自己学习，博客会记录自己的学习经历，包括付费课程，博客，书籍等等。
这是从零开始系列的第一天，往后的日子还有很长，希望自己能够一直坚持下去，不要忘记自己的初心，努力成为一个技术大牛！

## Hadoop -- 极客时间系列

最近在通过极客时间学习大数据，所以就先以这个作为起点。
### MR处理流程
课程内容以haddop 1来介绍MR的作业机制：
MR运行过程涉及三类关键进程：
1.大数据应用进程，是启动MR程序的主入口，也就是用户按照MR框架实现的业务处理程序
2.JobTracker进程，整个集群全局唯一，负责命令TaskTracker进程启动相应数量的Map和Reduce进程任务，并管理整个作业生命周期的任务调度和监控
3.TaskTracker进程，负责启动和管理Map进程和Reduce进程，常与DataNode在一个服务器中

MR运行流程：
![](https://static001.geekbang.org/resource/image/2d/27/2df4e1976fd8a6ac4a46047d85261027.png)

大致步骤:
1.Client将用户作业JAR包存储在HDFS中，后续JAR包回被分发给Hadoop集群中的服务器执行MR计算
2.Client提交JOB作业给JobTracker
3.JobTracker根据作业策略创建JobInProcess树，每个作业都会有一颗属于自己的树
4.JobInProcess根据输入数据分片数(通常是数据块的数目)，和设置的Reduce数目创建相应数量的TaskInProcess
5.TaskTracker与JobTracker进行定时通信
6.当TaskTracker有空闲计算资源时，JobTracker就会将任务分配给它，同时会将TaskTracker所在服务器上的数据块给它
7.TaskTracker收到任务后根据任务类型和任务参数，启动相应的Map或Reduce进程
8.进程启动后，检查本地是否有要执行的JAR包文件，如果没有则去HDFS上下载
9.Map进程会从本机数据块中读取数据进行计算，Reduce进程会将数据写到HDFS上

### Shuffle
每个 Map 任务的计算结果都会写入到本地文件系统，等 Map 任务快要计算完成的时候，MapReduce 计算框架会启动 shuffle 过程。在 Map 任务进程调用一个 Partitioner 接口，对 Map 产生的每个 进行 Reduce 分区选择，然后通过 HTTP 通信发送给对应的 Reduce 所在的服务器。相同的 Key 一定会被发送给相同的 Reduce 服务器上。
一个Key对应一个Reduce，但是一个Reduce可以对应dogeKey
简而言之就是，Shuffle过程就是为每个Map进程输出结果中的Key寻找对应的Reduce服务器

### Hadoop1 设计中主要的缺陷
服务器集群资源调度管理和MR执行过程耦合

### Yarn
分布式集群资源调度框架Yarn
架构图：
![](https://static001.geekbang.org/resource/image/af/b1/af90905013e5869f598c163c09d718b1.jpg)

### 组成
* 资源管理器(Resource Manager):负责整个集群的资源调度管理
    * 调度器: 一种资源分配算法
    * 应用程序管理器：负责应用程序的提交、监控程序运行状态
* 节点管理器(Node Manager):负责具体服务器上的资源和任务管理

Yarn进行资源分配的单位是容器

### Yarn工作流程
1.Client向Yarn提交应用程序，包括 MapReduce ApplicationMaster、我们的 MapReduce 程序，以及 MapReduce Application 启动命令
2.ResourceManager 进程和 NodeManager 进程通信，根据集群资源，为用户程序分配一个容器，并将 MapReduce ApplicationMaster 分发到这个容器上面，并在容器里面启动 MapReduce ApplicationMaster。
3.MR ApplicationMaster启动后向ResourceManager进程注册并申请容器资源
4.MR ApplicationMaster申请到需要的容器资源后，与相应的NodeManager通信，将用户MR程序分发到NodeManager所在的服务器上，在其上的容器中运行Map或Reduce任务
5.任务运行期间与MR ApplicationMaster通信，汇报运行状态，结束后，MR ApplicationMaster会向ResourceManager注销并释放所有的容器资源

Yarn 作为一个大数据资源调度框架，调度的是大数据计算引擎本身

### 依赖倒置原则
高层模块不能依赖低层模块，它们应共同依赖一个抽象，这个抽象由高层模块定义，由底层模块实现
高层和低层如何划分：
个人理解可以参考通信协议的OSI七层模型
模型上方的是高层，下方的是低层。


